# DLAI5
## Домашнее задание к уроку 5: Аугментации и работа с изображениями
### Задание 1: Стандартные аугментации torchvision
Для тестирования были выбраны следующие методы аугментации (их реализации были взяты из библиотеки torchvision):
 - RandomHorizontalFlip
 - RandomCrop
 - ColorJitter
 - RandomRotation
 - RandomGrayscale

Далее эти аугментации были применены к 5 случайно выбранным изображениям из предоставленного датасета. Были получены следующие результаты:

![stand_augs.png](results%2Fstand_augs%2Fstand_augs.png)

Из этого рисунка можно сделать следующие выводы:
 - RandomHorizontalFlip. "Переворачивает" изображение по оси Y. Слабая аугментация, полезна для симметричных объектов и обычно используется в сочетании с другими.
 - RandomCrop. Обрезает изображение до необходимого размера. Средняя по силе аугментация, помогает модели научиться работать с неполными объектами и разным контекстом.
 - ColorJitter. Меняет яркость, контрастность, насыщенность и оттенок изображения. Средне-сильная аугментация, разнообразит цвета и освещение, снижая переобучение к цветовым особенностям.
 - RandomRotation. На случайный градус вращает изображение по центру. Средняя по силе аугментация, подходит для данных, где ориентация объектов может различаться.
 - RandomGrayscale. Преобразует изображение в чёрно-белое. Достаточно сильная аугментация, полезна, если важно, чтобы модель работала и с цветными, и с чёрно-белыми изображениями.
 - Применение всех аугментаций вместе иногда создаёт достаточно отличающееся от начального изображение.

### Задание 2: Кастомные аугментации
На этом этапе мною были написаны следующие кастомные методы аугментации:
 - RandomBlur
 - RandomPerspective
 - RandomBrightnessContrast

Для сравнения также использовались следующие методы:
 - AddGaussianNoise
 - CutOut
 - ElasticTransform

![custom_augs.png](results%2Fcustom_augs%2Fcustom_augs.png)

Проанализируем этот рисунок:
 - RandomBlur. Размывает изображение, снижая чёткость деталей. Слабая или средняя аугментация, помогает модели стать устойчивее к «смазанным» данным и шуму фокуса.
 - RandomPerspective. Искажает изображение, меняя перспективу и геометрию. Достаточно сильная аугментация, полезна при работе с объектами под разными углами или в разных ракурсах.
 - RandomBrightnessContrast. Изменяет яркость и контраст изображения. Слабая или средняя аугментация, помогает модели быть менее чувствительной к условиям освещения.
 - AddGaussianNoise. Добавляет к изображению случайный гауссов шум. Средне-сильная аугментация, хорошо защищает от переобучения на идеально чистых данных.
 - CutOut. Закрашивает часть изображения прямоугольной маской. Сильная аугментация, принуждает модель опираться на контекст и неполные данные.
 - ElasticTransform. Деформирует изображение волнообразными искажениями. Средне-сильная или сильная аугментация, особенно эффективна в задачах, где форма объектов может меняться.

### Задание 3: Анализ датасета
На этом этапе мною было подсчитано количество изображений в каждом классе и найдены минимальный, максимальный и средний размеры изображений. Результаты можно увидеть на графиках, представленных ниже.

|      | width  | height  | area      |
|------|--------|---------|-----------|
| min  | 210.00 | 240.00  | 50400.00  |
| max  | 736.00 | 1308.00 | 962688.00 |
| mean | 538.89 | 623.59  | 344670.86 |

![areas_distribution.png](results%2Fanalysis%2Fareas_distribution.png)

Как можно увидеть, большая часть площадей изображений находится в интервале от 160000 до 500000. Также можно заметить наличие "выбросов" с площадью, близкой к 1000000.

![images_numbers.png](results%2Fanalysis%2Fimages_numbers.png)

По данной гистограмме модно увидеть, что во всех классах одинакове количество картинок (30).

### Задание 4: Pipeline аугментаций
Реализовал класс AugmentationPipeline со следующими методами:
 - add_augmentation(name, aug)
 - remove_augmentation(name)
 - apply(image)
 - get_augmentations()

Далее создал три разных пайплайна:
 - light (RandomErasing)
 - medium (RandomErasing, Posterize)
 - heavy (CutOut, RandomPerspective, Solarize, AutoContrast)

После этого каждый пайплайн был применён к случайным рисункам.

light:

![pipeline_light.png](results%2Fpipeline_tests%2Fpipeline_light.png)

Как видим, лёгкий пайплайн просто закрашивает часть изображения прямоугольной маской. Этого уже может быть достаточно для аугментации, но можно добавить ещё методов.

medium:

![pipeline_medium.png](results%2Fpipeline_tests%2Fpipeline_medium.png)

В среднем пайплайне после CutOut был добавлен метод Polarize. Новый метод уменьшает количество битов на каждом канале. Также можно заметить, как маска добавилась для последнего изображения. Это может стать достаточно сложным изображением для модели, ведь на нём нужно будет "смотреть" либо на фон, либо на волосы, одежду и тело.

heavy:

![pipeline_heavy.png](results%2Fpipeline_tests%2Fpipeline_heavy.png)

На последнем, сложном пайплайне использовались новые слои. Solarize. Инвертирует пикселей, значения которых превышают заранее определённое значение. AutoContrast. Увеличивает контраст изображения. С таким пайплайном уже следует орбращаться осторожно, так как есть риск потерять всю сколько-то важную информацию, например, при сильном изменении перспективы.

### Задание 5: Эксперимент с размерами
На этом этапе мною были проведены эксперименты на то, как влияет размер изображений датасета на производительность. Использовались следующие размеры: 64x64, 128x128, 224x224, 512x512.

Затрачиваемая память:

![memory.png](results%2Fperformance_test%2Fmemory.png)

Видим постепенное увеличение затрачиваемой памяти до размера 224х224 и резкий скачок вверх (примерно в 5 раз) на размере 512х512. Можно сделать вывод, что размер 224х224 и близкие к нему является пороговым и после идёт сильное ухудшение производительности.

Время на 100 изображений:

![time.png](results%2Fperformance_test%2Ftime.png)

Можно сделать все те же выводы, что и на графике с затрачиваемой памятью.

### Задание 6: Дообучение предобученных моделей
В этом задании я использовал модель efficientnet_b0.

Кривая обучения модели:

![learning_curve.png](results%2Fefficientnet%2Flearning_curve.png)

Как можно увидеть по графику, в процессе обучения была достигнута достаточно высокая точность, но на поздних эпохах модель начала переобучаться. Я думаю, что это произошло из-за слишком маленького размера датасета (150 картинок).